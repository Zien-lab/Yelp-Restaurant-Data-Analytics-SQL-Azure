{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.14",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [
        {
          "sourceId": 3316532,
          "sourceType": "datasetVersion",
          "datasetId": 10100
        }
      ],
      "dockerImageVersionId": 30786,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": false
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# This Python 3 environment comes with many helpful analytics libraries installed\n",
        "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
        "# For example, here's several helpful packages to load\n",
        "\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "\n",
        "# Input data files are available in the read-only \"../input/\" directory\n",
        "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
        "import json\n",
        "import os\n",
        "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
        "    for filename in filenames:\n",
        "        print(os.path.join(dirname, filename))\n",
        "\n",
        "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\"\n",
        "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "execution": {
          "iopub.status.busy": "2024-11-03T22:11:44.554876Z",
          "iopub.execute_input": "2024-11-03T22:11:44.555264Z",
          "iopub.status.idle": "2024-11-03T22:11:45.788515Z",
          "shell.execute_reply.started": "2024-11-03T22:11:44.555212Z",
          "shell.execute_reply": "2024-11-03T22:11:45.787187Z"
        },
        "trusted": true,
        "id": "pWXkZm9b9NIK",
        "outputId": "03e9f75b-97a4-412a-e6a0-0a4f803eac82"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "/kaggle/input/yelp-dataset/Dataset_User_Agreement.pdf\n/kaggle/input/yelp-dataset/yelp_academic_dataset_review.json\n/kaggle/input/yelp-dataset/yelp_academic_dataset_checkin.json\n/kaggle/input/yelp-dataset/yelp_academic_dataset_business.json\n/kaggle/input/yelp-dataset/yelp_academic_dataset_tip.json\n/kaggle/input/yelp-dataset/yelp_academic_dataset_user.json\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Convert JSON data to a Pandas DataFrame and explore the structure, time period, and scope of the data."
      ],
      "metadata": {
        "id": "FL-urfHh9NIL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Checkin"
      ],
      "metadata": {
        "id": "aEd_E4GP9NIM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "file_checkin = open(\"/kaggle/input/yelp-dataset/yelp_academic_dataset_checkin.json\")\n",
        "checkin = []\n",
        "for line in file_checkin:\n",
        "    checkin.append(json.loads(line))\n",
        "\n",
        "records = []\n",
        "for entry in checkin:\n",
        "    business_id = entry['business_id']\n",
        "    date = entry['date'].split(\", \")\n",
        "\n",
        "    for time in date:\n",
        "        records.append({\n",
        "            'business_id': business_id,\n",
        "            'date': time\n",
        "        })\n",
        "checkin_df = pd.DataFrame(records)\n",
        "print(checkin_df.head())\n",
        "#checkin_df.to_csv(\"checkin_data.csv\",index=False)\n",
        "file_checkin.close()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-11-03T22:23:07.162424Z",
          "iopub.execute_input": "2024-11-03T22:23:07.162902Z",
          "iopub.status.idle": "2024-11-03T22:23:28.706708Z",
          "shell.execute_reply.started": "2024-11-03T22:23:07.162859Z",
          "shell.execute_reply": "2024-11-03T22:23:28.705143Z"
        },
        "trusted": true,
        "id": "1mAwiAqH9NIM",
        "outputId": "b2aff1e3-4a1b-4f2d-cd93-cd20971aecda"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "              business_id                 date\n0  ---kPU91CF4Lq2-WlRu9Lw  2020-03-13 21:10:56\n1  ---kPU91CF4Lq2-WlRu9Lw  2020-06-02 22:18:06\n2  ---kPU91CF4Lq2-WlRu9Lw  2020-07-24 22:42:27\n3  ---kPU91CF4Lq2-WlRu9Lw  2020-10-24 21:36:13\n4  ---kPU91CF4Lq2-WlRu9Lw  2020-12-09 21:23:33\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Business"
      ],
      "metadata": {
        "id": "UT3YvZDH9NIN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "file_business = open(\"/kaggle/input/yelp-dataset/yelp_academic_dataset_business.json\")\n",
        "business = []\n",
        "for line in file_business:\n",
        "    business.append(json.loads(line))\n",
        "\n",
        "business_df = pd.json_normalize(business)\n",
        "\n",
        "business_df['categories'] = business_df['categories'].str.split(\", \")\n",
        "\n",
        "#business_df.to_excel(\"business_data.xlsx\", index=False)\n",
        "print(business_df.head())\n",
        "file_business.close()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-11-03T23:05:16.407881Z",
          "iopub.execute_input": "2024-11-03T23:05:16.408540Z",
          "iopub.status.idle": "2024-11-03T23:05:30.241486Z",
          "shell.execute_reply.started": "2024-11-03T23:05:16.408462Z",
          "shell.execute_reply": "2024-11-03T23:05:30.239699Z"
        },
        "trusted": true,
        "id": "MIncg1PD9NIN",
        "outputId": "7fcc1105-b6cd-4707-9127-6fb7cd211e4e"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "              business_id                      name  \\\n0  Pns2l4eNsfO8kk83dixA6A  Abby Rappoport, LAC, CMQ   \n1  mpf3x-BjTdTEA3yCZrAYPw             The UPS Store   \n2  tUFrWirKiKi_TAnsVWINQQ                    Target   \n3  MTSW4McQd7CbVtyjqoe9mw        St Honore Pastries   \n4  mWMc6_wTdE0EUBKIGXDVfA  Perkiomen Valley Brewery   \n\n                           address           city state postal_code  \\\n0           1616 Chapala St, Ste 2  Santa Barbara    CA       93101   \n1  87 Grasso Plaza Shopping Center         Affton    MO       63123   \n2             5255 E Broadway Blvd         Tucson    AZ       85711   \n3                      935 Race St   Philadelphia    PA       19107   \n4                    101 Walnut St     Green Lane    PA       18054   \n\n    latitude   longitude  stars  review_count  ...  \\\n0  34.426679 -119.711197    5.0             7  ...   \n1  38.551126  -90.335695    3.0            15  ...   \n2  32.223236 -110.880452    3.5            22  ...   \n3  39.955505  -75.155564    4.0            80  ...   \n4  40.338183  -75.471659    4.5            13  ...   \n\n   attributes.AcceptsInsurance attributes.BestNights  attributes.BYOB  \\\n0                          NaN                   NaN              NaN   \n1                          NaN                   NaN              NaN   \n2                          NaN                   NaN              NaN   \n3                          NaN                   NaN              NaN   \n4                          NaN                   NaN              NaN   \n\n  attributes.Corkage attributes.BYOBCorkage attributes.HairSpecializesIn  \\\n0                NaN                    NaN                          NaN   \n1                NaN                    NaN                          NaN   \n2                NaN                    NaN                          NaN   \n3                NaN                    NaN                          NaN   \n4                NaN                    NaN                          NaN   \n\n  attributes.Open24Hours attributes.RestaurantsCounterService  \\\n0                    NaN                                  NaN   \n1                    NaN                                  NaN   \n2                    NaN                                  NaN   \n3                    NaN                                  NaN   \n4                    NaN                                  NaN   \n\n  attributes.AgesAllowed attributes.DietaryRestrictions  \n0                    NaN                            NaN  \n1                    NaN                            NaN  \n2                    NaN                            NaN  \n3                    NaN                            NaN  \n4                    NaN                            NaN  \n\n[5 rows x 60 columns]\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Riview"
      ],
      "metadata": {
        "id": "IAvg62fN9NIN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "file_review = open(\"/kaggle/input/yelp-dataset/yelp_academic_dataset_review.json\")\n",
        "\n",
        "chunk_size = 10000\n",
        "review_chunks = []\n",
        "review_df = pd.DataFrame()\n",
        "\n",
        "for i, line in enumerate(file_review):\n",
        "    try:\n",
        "        review_data = json.loads(line)\n",
        "        review_chunks.append(review_data)\n",
        "\n",
        "        if (i + 1) % chunk_size == 0:\n",
        "            chunk_df = pd.json_normalize(review_chunks)\n",
        "            review_chunks = []\n",
        "\n",
        "            review_df = pd.concat([review_df, chunk_df], ignore_index=True)\n",
        "\n",
        "    except json.JSONDecodeError as e:\n",
        "        print(f\"JSON decode error at line {i}: {e}\")\n",
        "\n",
        "if review_chunks:\n",
        "    chunk_df = pd.json_normalize(review_chunks)\n",
        "    review_df = pd.concat([review_df, chunk_df], ignore_index=True)\n",
        "\n",
        "print(review_df.head())\n",
        "#review_df.to_csv(\"review_data.csv\",index=False)\n",
        "file_review.close()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-11-03T22:23:51.581399Z",
          "iopub.execute_input": "2024-11-03T22:23:51.581820Z",
          "iopub.status.idle": "2024-11-03T22:36:35.401285Z",
          "shell.execute_reply.started": "2024-11-03T22:23:51.581781Z",
          "shell.execute_reply": "2024-11-03T22:36:35.399378Z"
        },
        "trusted": true,
        "id": "dvW4cEQm9NIN",
        "outputId": "d7556d72-7e12-40d9-b4d4-30aa11bb5505"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "                review_id                 user_id             business_id  \\\n0  KU_O5udG6zpxOg-VcAEodg  mh_-eMZ6K5RLWhZyISBhwA  XQfwVwDr-v0ZS3_CbbE5Xw   \n1  BiTunyQ73aT9WBnpR9DZGw  OyoGAe7OKpv6SyGZT5g77Q  7ATYjTIgM3jUlt4UM3IypQ   \n2  saUsX_uimxRlCVr67Z4Jig  8g_iMtfSiwikVnbP2etR0A  YjUWPpI6HXG530lwP-fb2A   \n3  AqPFMleE6RsU23_auESxiA  _7bHUi9Uuf5__HHc_Q8guQ  kxX2SOes4o-D3ZQBkiMRfA   \n4  Sx8TMOWLNuJBWer-0pcmoA  bcjbaE6dDog4jkNY91ncLQ  e4Vwtrqf-wpJfwesgvdgxQ   \n\n   stars  useful  funny  cool  \\\n0    3.0       0      0     0   \n1    5.0       1      0     1   \n2    3.0       0      0     0   \n3    5.0       1      0     1   \n4    4.0       1      0     1   \n\n                                                text                 date  \n0  If you decide to eat here, just be aware it is...  2018-07-07 22:09:11  \n1  I've taken a lot of spin classes over the year...  2012-01-03 15:28:18  \n2  Family diner. Had the buffet. Eclectic assortm...  2014-02-05 20:30:30  \n3  Wow!  Yummy, different,  delicious.   Our favo...  2015-01-04 00:01:03  \n4  Cute interior and owner (?) gave us tour of up...  2017-01-14 20:54:15  \n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tip"
      ],
      "metadata": {
        "id": "bPquEM0C9NIO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "file_tip = open(\"/kaggle/input/yelp-dataset/yelp_academic_dataset_tip.json\")\n",
        "tip = []\n",
        "for line in file_tip:\n",
        "    tip.append(json.loads(line))\n",
        "\n",
        "tip_df = pd.json_normalize(tip)\n",
        "print(tip_df.head())\n",
        "#tip_df.to_csv(\"tip_data.csv\",index=False)\n",
        "file_tip.close()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-11-03T22:40:58.372398Z",
          "iopub.execute_input": "2024-11-03T22:40:58.373038Z",
          "iopub.status.idle": "2024-11-03T22:41:12.933069Z",
          "shell.execute_reply.started": "2024-11-03T22:40:58.372988Z",
          "shell.execute_reply": "2024-11-03T22:41:12.931530Z"
        },
        "trusted": true,
        "id": "GmKzEIsm9NIO",
        "outputId": "eeb4da9c-7e00-4c50-f0b7-fd29787200f7"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "                  user_id             business_id  \\\n0  AGNUgVwnZUey3gcPCJ76iw  3uLgwr0qeCNMjKenHJwPGQ   \n1  NBN4MgHP9D3cw--SnauTkA  QoezRbYQncpRqyrLH6Iqjg   \n2  -copOvldyKh1qr-vzkDEvw  MYoRNLb5chwjQe3c_k37Gg   \n3  FjMQVZjSqY8syIO-53KFKw  hV-bABTK-glh5wj31ps_Jw   \n4  ld0AperBXk1h6UbqmM80zw  _uN0OudeJ3Zl_tf6nxg5ww   \n\n                                                text                 date  \\\n0                     Avengers time with the ladies.  2012-05-18 02:17:21   \n1  They have lots of good deserts and tasty cuban...  2013-02-05 18:35:10   \n2             It's open even when you think it isn't  2013-08-18 00:56:08   \n3                          Very decent fried chicken  2017-06-27 23:05:38   \n4             Appetizers.. platter special for lunch  2012-10-06 19:43:09   \n\n   compliment_count  \n0                 0  \n1                 0  \n2                 0  \n3                 0  \n4                 0  \n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# User"
      ],
      "metadata": {
        "id": "u8aQH80W9NIO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "file_user = open(\"/kaggle/input/yelp-dataset/yelp_academic_dataset_user.json\")\n",
        "\n",
        "chunk_size = 10000\n",
        "user_chunks = []\n",
        "user_df = pd.DataFrame()\n",
        "\n",
        "for i, line in enumerate(file_user):\n",
        "    try:\n",
        "        user_data = json.loads(line)\n",
        "        user_chunks.append(user_data)\n",
        "\n",
        "        if (i + 1) % chunk_size == 0:\n",
        "            chunk_df = pd.json_normalize(user_chunks)\n",
        "            user_chunks = []\n",
        "\n",
        "            user_df = pd.concat([user_df, chunk_df], ignore_index=True)\n",
        "\n",
        "    except json.JSONDecodeError as e:\n",
        "        print(f\"JSON decode error at line {i}: {e}\")\n",
        "\n",
        "if user_chunks:\n",
        "    chunk_df = pd.json_normalize(user_chunks)\n",
        "    user_df = pd.concat([user_df, chunk_df], ignore_index=True)\n",
        "\n",
        "print(user_df.head())\n",
        "# user_df['friends'] = user_df['friends'].str.split(\", \")\n",
        "# user_df['elite'] = user_df['elite'].str.split(\", \")\n",
        "# user_df.to_csv(\"user_data.csv\", index=False)\n",
        "file_user.close()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-11-03T16:52:53.091928Z",
          "iopub.execute_input": "2024-11-03T16:52:53.092332Z",
          "iopub.status.idle": "2024-11-03T16:55:47.766113Z",
          "shell.execute_reply.started": "2024-11-03T16:52:53.092290Z",
          "shell.execute_reply": "2024-11-03T16:55:47.764930Z"
        },
        "trusted": true,
        "id": "Jfqv16zR9NIO",
        "outputId": "3c2b21ad-e5d2-4fd2-e3d7-b5aa92c88c61"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "                  user_id    name  review_count        yelping_since  useful  \\\n0  qVc8ODYU5SZjKXVBgXdI7w  Walker           585  2007-01-25 16:47:26    7217   \n1  j14WgRoU_-2ZE1aw1dXrJg  Daniel          4333  2009-01-25 04:35:42   43091   \n2  2WnXYQFK0hXEoTxPtV2zvg   Steph           665  2008-07-25 10:41:00    2086   \n3  SZDeASXq7o05mMNLshsdIA    Gwen           224  2005-11-29 04:38:33     512   \n4  hA5lMy-EnncsH4JoR-hFGQ   Karen            79  2007-01-05 19:40:59      29   \n\n   funny   cool                                              elite  \\\n0   1259   5994                                               2007   \n1  13066  27281  2009,2010,2011,2012,2013,2014,2015,2016,2017,2...   \n2   1010   1003                           2009,2010,2011,2012,2013   \n3    330    299                                     2009,2010,2011   \n4     15      7                                                      \n\n                                             friends  fans  ...  \\\n0  NSCy54eWehBJyZdG2iE84w, pe42u7DcCH2QmI81NX-8qA...   267  ...   \n1  ueRPE0CX75ePGMqOFVj6IQ, 52oH4DrRvzzl8wh5UXyU0A...  3138  ...   \n2  LuO3Bn4f3rlhyHIaNfTlnA, j9B4XdHUhDfTKVecyWQgyA...    52  ...   \n3  enx1vVPnfdNUdPho6PH_wg, 4wOcvMLtU6a9Lslggq74Vg...    28  ...   \n4  PBK4q9KEEBHhFvSXCUirIw, 3FWPpM7KU1gXeOM_ZbYMbA...     1  ...   \n\n   compliment_more  compliment_profile  compliment_cute  compliment_list  \\\n0               65                  55               56               18   \n1              264                 184              157              251   \n2               13                  10               17                3   \n3                4                   1                6                2   \n4                1                   0                0                0   \n\n   compliment_note  compliment_plain  compliment_cool  compliment_funny  \\\n0              232               844              467               467   \n1             1847              7054             3131              3131   \n2               66                96              119               119   \n3               12                16               26                26   \n4                1                 1                0                 0   \n\n   compliment_writer  compliment_photos  \n0                239                180  \n1               1521               1946  \n2                 35                 18  \n3                 10                  9  \n4                  0                  0  \n\n[5 rows x 22 columns]\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "OTRfByi09NIO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Set up the environment and connect to the database using the IP address and adjust the dataframe to upload it to the Azure database"
      ],
      "metadata": {
        "id": "_Cw4seqp9NIO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sqlalchemy import create_engine\n",
        "import sqlalchemy\n",
        "!pip install pyodbc\n",
        "!pip install sqlalchemy\n",
        "!apt-get install -y unixodbc-dev\n",
        "\n",
        "!curl https://packages.microsoft.com/keys/microsoft.asc | apt-key add -\n",
        "!curl https://packages.microsoft.com/config/ubuntu/$(lsb_release -rs)/prod.list > /etc/apt/sources.list.d/mssql-release.list\n",
        "!apt-get update\n",
        "!ACCEPT_EULA=Y apt-get install -y msodbcsql17"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-11-03T22:53:18.575749Z",
          "iopub.execute_input": "2024-11-03T22:53:18.576472Z",
          "iopub.status.idle": "2024-11-03T22:54:04.724613Z",
          "shell.execute_reply.started": "2024-11-03T22:53:18.576414Z",
          "shell.execute_reply": "2024-11-03T22:54:04.722784Z"
        },
        "trusted": true,
        "id": "o6_fIdl79NIO",
        "outputId": "8ee6b844-b527-4403-fec1-7aa8a22694c7"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Requirement already satisfied: pyodbc in /opt/conda/lib/python3.10/site-packages (5.2.0)\nRequirement already satisfied: sqlalchemy in /opt/conda/lib/python3.10/site-packages (2.0.30)\nRequirement already satisfied: typing-extensions>=4.6.0 in /opt/conda/lib/python3.10/site-packages (from sqlalchemy) (4.12.2)\nRequirement already satisfied: greenlet!=0.4.17 in /opt/conda/lib/python3.10/site-packages (from sqlalchemy) (3.0.3)\nReading package lists... Done\nBuilding dependency tree       \nReading state information... Done\nunixodbc-dev is already the newest version (2.3.11-1).\n0 upgraded, 0 newly installed, 0 to remove and 58 not upgraded.\n  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n                                 Dload  Upload   Total   Spent    Left  Speed\n100   983  100   983    0     0  10215      0 --:--:-- --:--:-- --:--:-- 10239\nOK\n  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n                                 Dload  Upload   Total   Spent    Left  Speed\n100    89  100    89    0     0    955      0 --:--:-- --:--:-- --:--:--   956\nHit:1 https://packages.cloud.google.com/apt gcsfuse-focal InRelease\nHit:2 https://packages.microsoft.com/ubuntu/20.04/prod focal InRelease\nHit:3 http://archive.ubuntu.com/ubuntu focal InRelease              \nHit:4 http://security.ubuntu.com/ubuntu focal-security InRelease    \nHit:5 http://archive.ubuntu.com/ubuntu focal-updates InRelease\nHit:6 https://packages.cloud.google.com/apt cloud-sdk InRelease\nHit:7 http://archive.ubuntu.com/ubuntu focal-backports InRelease\nReading package lists... Done\nReading package lists... Done\nBuilding dependency tree       \nReading state information... Done\nmsodbcsql17 is already the newest version (17.10.6.1-1).\n0 upgraded, 0 newly installed, 0 to remove and 58 not upgraded.\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sqlalchemy import create_engine\n",
        "import sqlalchemy\n",
        "!pip install pyodbc\n",
        "!pip install sqlalchemy\n",
        "\n",
        "# Define connection details\n",
        "username = 'sqladmin'  # Replace with your Azure SQL admin username\n",
        "password = 'MINIproject11'        # Replace with your Azure SQL password\n",
        "server = 'zienzhu2-server.database.windows.net'\n",
        "database = 'mini-project-db'\n",
        "\n",
        "# Connection string for Azure SQL Server\n",
        "connection_string = f\"mssql+pyodbc://{username}:{password}@{server}:1433/{database}?driver=ODBC+Driver+17+for+SQL+Server\"\n",
        "engine = create_engine(connection_string)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-11-03T22:55:58.845693Z",
          "iopub.execute_input": "2024-11-03T22:55:58.846317Z",
          "iopub.status.idle": "2024-11-03T22:56:28.815304Z",
          "shell.execute_reply.started": "2024-11-03T22:55:58.846245Z",
          "shell.execute_reply": "2024-11-03T22:56:28.813927Z"
        },
        "trusted": true,
        "id": "33D2AwGM9NIP",
        "outputId": "c1de5448-ec00-4cee-d0a1-7d72adaf0a9b"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Requirement already satisfied: pyodbc in /opt/conda/lib/python3.10/site-packages (5.2.0)\nRequirement already satisfied: sqlalchemy in /opt/conda/lib/python3.10/site-packages (2.0.30)\nRequirement already satisfied: typing-extensions>=4.6.0 in /opt/conda/lib/python3.10/site-packages (from sqlalchemy) (4.12.2)\nRequirement already satisfied: greenlet!=0.4.17 in /opt/conda/lib/python3.10/site-packages (from sqlalchemy) (3.0.3)\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "# GET IP\n",
        "ip_address = requests.get('https://api64.ipify.org').text\n",
        "print(\"Your IP address is:\", ip_address)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-11-03T22:58:06.507452Z",
          "iopub.execute_input": "2024-11-03T22:58:06.508044Z",
          "iopub.status.idle": "2024-11-03T22:58:06.836656Z",
          "shell.execute_reply.started": "2024-11-03T22:58:06.507990Z",
          "shell.execute_reply": "2024-11-03T22:58:06.835011Z"
        },
        "trusted": true,
        "id": "L0f3kOZp9NIP",
        "outputId": "49db463f-6bc1-44f5-9033-466c53f2bf9a"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Your IP address is: 35.230.36.89\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tip_df.to_sql(name=\"tip_df\", con=engine, if_exists='replace', index=False, chunksize=5000)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-11-03T23:01:23.502347Z",
          "iopub.execute_input": "2024-11-03T23:01:23.502900Z",
          "iopub.status.idle": "2024-11-03T23:03:56.429164Z",
          "shell.execute_reply.started": "2024-11-03T23:01:23.502852Z",
          "shell.execute_reply": "2024-11-03T23:03:56.427894Z"
        },
        "trusted": true,
        "id": "QcdL00T29NIP",
        "outputId": "535f8003-7f91-4c3d-eeb6-e4ac38ac9429"
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 13,
          "output_type": "execute_result",
          "data": {
            "text/plain": "70915"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "review_df.to_sql(name=\"review_df\", con=engine, if_exists='replace', index=False, chunksize=5000)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-11-04T00:29:21.328188Z",
          "iopub.execute_input": "2024-11-04T00:29:21.329052Z",
          "iopub.status.idle": "2024-11-04T01:33:28.376889Z",
          "shell.execute_reply.started": "2024-11-04T00:29:21.328993Z",
          "shell.execute_reply": "2024-11-04T01:33:28.375617Z"
        },
        "trusted": true,
        "id": "8Swk5Bjj9NIP",
        "outputId": "0060d3ed-db87-4eeb-8b6e-15784712e81a"
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 17,
          "output_type": "execute_result",
          "data": {
            "text/plain": "149633"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "user_df.to_sql(name=\"user_df\", con=engine, if_exists='replace', index=False, chunksize=5000)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-11-03T16:56:55.529765Z",
          "iopub.status.idle": "2024-11-03T16:56:55.530255Z",
          "shell.execute_reply.started": "2024-11-03T16:56:55.530006Z",
          "shell.execute_reply": "2024-11-03T16:56:55.530030Z"
        },
        "trusted": true,
        "id": "SVWI1_HL9NIP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Because the business table is special, we need to adjust its JSON format,\n",
        "# otherwise one of its columns called categories will become null.\n",
        "\n",
        "import pandas as pd\n",
        "import json\n",
        "from sqlalchemy import create_engine\n",
        "import sqlalchemy\n",
        "\n",
        "# Convert data of dict type to JSON string format\n",
        "business_df['attributes'] = business_df['attributes'].apply(lambda x: json.dumps(x) if isinstance(x, dict) else x)\n",
        "business_df['hours'] = business_df['hours'].apply(lambda x: json.dumps(x) if isinstance(x, dict) else x)\n",
        "\n",
        "# Upload to the database, specifying data types\n",
        "business_df.to_sql(\n",
        "    name=\"business_df\",\n",
        "    con=engine,\n",
        "    if_exists='replace',\n",
        "    index=True,\n",
        "    dtype={\n",
        "        'attributes': sqlalchemy.types.NVARCHAR,\n",
        "        'hours': sqlalchemy.types.NVARCHAR\n",
        "    },\n",
        "    chunksize=5000\n",
        ")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-11-03T23:06:54.090046Z",
          "iopub.execute_input": "2024-11-03T23:06:54.090784Z",
          "iopub.status.idle": "2024-11-03T23:21:23.117333Z",
          "shell.execute_reply.started": "2024-11-03T23:06:54.090725Z",
          "shell.execute_reply": "2024-11-03T23:21:23.115622Z"
        },
        "trusted": true,
        "id": "cuZj7PcV9NIP",
        "outputId": "52d12e94-9cc7-4335-b4b5-0ef2dbd05c05"
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 15,
          "output_type": "execute_result",
          "data": {
            "text/plain": "66"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "checkin_df.to_sql(name=\"checkin_df\", con=engine, if_exists='replace', index=False, chunksize=5000)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-11-03T16:56:55.534152Z",
          "iopub.status.idle": "2024-11-03T16:56:55.534561Z",
          "shell.execute_reply.started": "2024-11-03T16:56:55.534358Z",
          "shell.execute_reply": "2024-11-03T16:56:55.534379Z"
        },
        "trusted": true,
        "id": "qw3cYOqg9NIP"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}